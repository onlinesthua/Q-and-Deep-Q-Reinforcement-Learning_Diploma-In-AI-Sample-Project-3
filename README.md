This project focuses on the implementation of Q-learning and Deep Q-learning methods to solve reinforcement learning problems. Reinforcement learning involves training agents to make sequential decisions in an environment to maximize cumulative rewards. Q-learning and Deep Q-learning are popular techniques used to address such problems, with Deep Q-learning leveraging neural networks to approximate the Q-function.

By implementing both algorithms from scratch, the project ensures a deep understanding of their underlying principles and the differences between them. They will explore how Q-learning updates Q-values based on observed rewards and learns an optimal policy over time, and how Deep Q-learning extends this approach by using neural networks to handle complex state-action spaces more effectively.

Potential uses:
1.	Game Playing: Training agents to play video games by learning from rewards and penalties.
2.	Robotics: Teaching robots to navigate and perform tasks in dynamic environments.
3.	Finance: Optimizing trading strategies based on historical market data and real-time feedback.

Learning outcomes:
1.	Understanding of Q-learning and Deep Q-learning algorithms and their applications in reinforcement learning.
2.	Proficiency in implementing these algorithms from scratch using Python and TensorFlow.
3.	Ability to analyze and compare the performance of Q-learning and Deep Q-learning in various environments.

This project is prepared by Chen Yijie under the supervision of Zhou Changxin.
